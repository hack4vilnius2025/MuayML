{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5825a28",
   "metadata": {},
   "source": [
    "# YOLOv11 Pose Estimation for Muay Thai\n",
    "\n",
    "This notebook uses YOLOv11 pose estimation to detect body keypoints in muay thai videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d2f3a3",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Check Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9629f096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics version: 8.3.228\n",
      "OpenCV version: 4.12.0\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check ultralytics version\n",
    "import ultralytics\n",
    "print(f\"Ultralytics version: {ultralytics.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a04199",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained YOLOv11 Pose Model\n",
    "\n",
    "YOLOv11 has pre-trained pose estimation models that detect 17 body keypoints:\n",
    "- 0: Nose, 1: Left Eye, 2: Right Eye, 3: Left Ear, 4: Right Ear\n",
    "- 5: Left Shoulder, 6: Right Shoulder, 7: Left Elbow, 8: Right Elbow\n",
    "- 9: Left Wrist, 10: Right Wrist, 11: Left Hip, 12: Right Hip\n",
    "- 13: Left Knee, 14: Right Knee, 15: Left Ankle, 16: Right Ankle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "add116b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv11 pose model to detect body parts\n",
    "# Options: yolo11n-pose.pt (nano), yolo11s-pose.pt (small), yolo11m-pose.pt (medium), yolo11l-pose.pt (large)\n",
    "model = YOLO('yolo11n-pose.pt')  # Nano model - FASTEST (10-30 FPS on GPU)\n",
    "# This will detect keypoints to draw boxes around body parts\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d328a",
   "metadata": {},
   "source": [
    "## 3. Process Your Video Directly (No Training Needed)\n",
    "\n",
    "Since we're using a pre-trained model, you can directly process your muay thai video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ca03602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 399 frames at 25 FPS...\n",
      "Processed 30/399 frames (7.5%)\n",
      "Processed 30/399 frames (7.5%)\n",
      "Processed 60/399 frames (15.0%)\n",
      "Processed 60/399 frames (15.0%)\n",
      "Processed 90/399 frames (22.6%)\n",
      "Processed 90/399 frames (22.6%)\n",
      "Processed 120/399 frames (30.1%)\n",
      "Processed 120/399 frames (30.1%)\n",
      "Processed 150/399 frames (37.6%)\n",
      "Processed 150/399 frames (37.6%)\n",
      "Processed 180/399 frames (45.1%)\n",
      "Processed 180/399 frames (45.1%)\n",
      "Processed 210/399 frames (52.6%)\n",
      "Processed 210/399 frames (52.6%)\n",
      "Processed 240/399 frames (60.2%)\n",
      "Processed 240/399 frames (60.2%)\n",
      "Processed 270/399 frames (67.7%)\n",
      "Processed 270/399 frames (67.7%)\n",
      "Processed 300/399 frames (75.2%)\n",
      "Processed 300/399 frames (75.2%)\n",
      "Processed 330/399 frames (82.7%)\n",
      "Processed 330/399 frames (82.7%)\n",
      "Processed 360/399 frames (90.2%)\n",
      "Processed 360/399 frames (90.2%)\n",
      "Processed 390/399 frames (97.7%)\n",
      "Processed 390/399 frames (97.7%)\n",
      "\n",
      "✓ Processing complete!\n",
      "Output saved to: runs/bodyparts/amateur1.mp4\n",
      "\n",
      "Body parts detected:\n",
      "  - HEAD (green)\n",
      "  - CHEST (blue)\n",
      "  - L_ELBOW (cyan)\n",
      "  - R_ELBOW (yellow)\n",
      "  - L_HAND (magenta)\n",
      "  - R_HAND (purple)\n",
      "  - L_TOES (orange)\n",
      "  - R_TOES (light orange)\n",
      "\n",
      "✓ Processing complete!\n",
      "Output saved to: runs/bodyparts/amateur1.mp4\n",
      "\n",
      "Body parts detected:\n",
      "  - HEAD (green)\n",
      "  - CHEST (blue)\n",
      "  - L_ELBOW (cyan)\n",
      "  - R_ELBOW (yellow)\n",
      "  - L_HAND (magenta)\n",
      "  - R_HAND (purple)\n",
      "  - L_TOES (orange)\n",
      "  - R_TOES (light orange)\n"
     ]
    }
   ],
   "source": [
    "# Process video with body part detection (head, torso, arms, legs)\n",
    "import numpy as np\n",
    "\n",
    "video_path = \"data/videos/amateur1.mov\"  # UPDATE THIS PATH\n",
    "output_path = \"runs/bodyparts/amateur1.mp4\"\n",
    "os.makedirs(\"runs/bodyparts\", exist_ok=True)\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "print(f\"Processing {total_frames} frames at {fps} FPS...\")\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run pose detection\n",
    "    results = model.predict(frame, device=0, conf=0.3, imgsz=416, half=True, verbose=False)\n",
    "    \n",
    "    if len(results[0].boxes) > 0:\n",
    "        # Get keypoints for each detected person\n",
    "        keypoints = results[0].keypoints.xy.cpu().numpy()\n",
    "        boxes = results[0].boxes.xywh.cpu().numpy()  # Person boxes\n",
    "        \n",
    "        for person_idx, kpts in enumerate(keypoints):\n",
    "            # Detect boxing gloves by checking hand/wrist area size and color\n",
    "            person_box = boxes[person_idx]\n",
    "            person_area = person_box[2] * person_box[3]  # width * height\n",
    "            \n",
    "            # Check for boxing gloves presence by analyzing wrist regions\n",
    "            has_gloves = False\n",
    "            glove_regions = []\n",
    "            \n",
    "            for wrist_idx in [9, 10]:  # Left and right wrists\n",
    "                if kpts[wrist_idx][0] > 0:\n",
    "                    wx, wy = kpts[wrist_idx].astype(int)\n",
    "                    # Sample larger area around wrist (gloves are bigger than bare hands)\n",
    "                    glove_size = 40\n",
    "                    y1, y2 = max(0, wy-glove_size), min(height, wy+glove_size)\n",
    "                    x1, x2 = max(0, wx-glove_size), min(width, wx+glove_size)\n",
    "                    \n",
    "                    if y2 > y1 and x2 > x1:\n",
    "                        wrist_region = frame[y1:y2, x1:x2]\n",
    "                        if wrist_region.size > 0:\n",
    "                            # Calculate average color saturation (gloves are usually bright colored)\n",
    "                            hsv = cv2.cvtColor(wrist_region, cv2.COLOR_BGR2HSV)\n",
    "                            avg_saturation = np.mean(hsv[:,:,1])\n",
    "                            \n",
    "                            # Boxing gloves typically have high saturation (bright colors)\n",
    "                            if avg_saturation > 50:  # Threshold for colored gloves\n",
    "                                has_gloves = True\n",
    "                                glove_regions.append((wx, wy))\n",
    "            \n",
    "            # Only process people with boxing gloves (fighters)\n",
    "            # Filter out background fighters by size - only keep the 2 largest detected people\n",
    "            if person_area > (width * height * 0.005) and has_gloves:\n",
    "                # Store person info for size comparison\n",
    "                continue\n",
    "        \n",
    "        # After checking all people, only process the 2 largest (main fighters in foreground)\n",
    "        if len(results[0].boxes) > 0:\n",
    "            # Get all fighters with gloves and their areas\n",
    "            fighters = []\n",
    "            for person_idx, kpts in enumerate(keypoints):\n",
    "                person_box = boxes[person_idx]\n",
    "                person_area = person_box[2] * person_box[3]\n",
    "                \n",
    "                # Check for gloves again\n",
    "                has_gloves = False\n",
    "                for wrist_idx in [9, 10]:\n",
    "                    if kpts[wrist_idx][0] > 0:\n",
    "                        wx, wy = kpts[wrist_idx].astype(int)\n",
    "                        glove_size = 40\n",
    "                        y1, y2 = max(0, wy-glove_size), min(height, wy+glove_size)\n",
    "                        x1, x2 = max(0, wx-glove_size), min(width, wx+glove_size)\n",
    "                        \n",
    "                        if y2 > y1 and x2 > x1:\n",
    "                            wrist_region = frame[y1:y2, x1:x2]\n",
    "                            if wrist_region.size > 0:\n",
    "                                hsv = cv2.cvtColor(wrist_region, cv2.COLOR_BGR2HSV)\n",
    "                                avg_saturation = np.mean(hsv[:,:,1])\n",
    "                                if avg_saturation > 50:\n",
    "                                    has_gloves = True\n",
    "                                    break\n",
    "                \n",
    "                if has_gloves and person_area > (width * height * 0.005):\n",
    "                    fighters.append((person_idx, person_area, kpts))\n",
    "            \n",
    "            # Sort by area (largest first) and take only top 2\n",
    "            fighters.sort(key=lambda x: x[1], reverse=True)\n",
    "            # Keep top 2 fighters if available, or just 1 if only one fighter detected\n",
    "            main_fighters = fighters[:min(2, len(fighters))]\n",
    "            \n",
    "            # Process only the main fighters\n",
    "            for person_idx, person_area, kpts in main_fighters:\n",
    "                \n",
    "                # Define body parts from keypoints (x, y coordinates)\n",
    "                # Keypoints: 0=nose, 5=L_shoulder, 6=R_shoulder, 7=L_elbow, 8=R_elbow,\n",
    "                #           9=L_wrist, 10=R_wrist, 11=L_hip, 12=R_hip, 13=L_knee, 14=R_knee, 15=L_ankle, 16=R_ankle\n",
    "                \n",
    "                # HEAD: nose, eyes, ears (keypoints 0-4)\n",
    "                head_kpts = kpts[0:5]\n",
    "                valid_head = head_kpts[head_kpts[:, 0] > 0]\n",
    "                if len(valid_head) > 0:\n",
    "                    x_min, y_min = valid_head.min(axis=0).astype(int)\n",
    "                    x_max, y_max = valid_head.max(axis=0).astype(int)\n",
    "                    padding = 20\n",
    "                    cv2.rectangle(frame, (x_min-padding, y_min-padding), (x_max+padding, y_max+padding), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, 'HEAD', (x_min-padding, y_min-padding-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                \n",
    "                # CHEST: shoulders only (keypoints 5,6)\n",
    "                chest_indices = [5, 6]\n",
    "                chest_kpts = kpts[chest_indices]\n",
    "                valid_chest = chest_kpts[chest_kpts[:, 0] > 0]\n",
    "                if len(valid_chest) > 1:\n",
    "                    x_min, y_min = valid_chest.min(axis=0).astype(int)\n",
    "                    x_max, y_max = valid_chest.max(axis=0).astype(int)\n",
    "                    # Extend down from shoulders to make chest area\n",
    "                    y_max = int(y_max + (y_max - y_min) * 1.5)  # Extend downward\n",
    "                    padding = 15\n",
    "                    cv2.rectangle(frame, (x_min-padding, y_min-padding), (x_max+padding, y_max+padding), (255, 0, 0), 2)\n",
    "                    cv2.putText(frame, 'CHEST', (x_min-padding, y_min-padding-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                \n",
    "                # LEFT ELBOW (keypoint 7)\n",
    "                if kpts[7][0] > 0:\n",
    "                    x, y = kpts[7].astype(int)\n",
    "                    box_size = 25\n",
    "                    cv2.rectangle(frame, (x-box_size, y-box_size), (x+box_size, y+box_size), (0, 255, 255), 2)\n",
    "                    cv2.putText(frame, 'L_ELBOW', (x-box_size, y-box_size-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 2)\n",
    "                \n",
    "                # RIGHT ELBOW (keypoint 8)\n",
    "                if kpts[8][0] > 0:\n",
    "                    x, y = kpts[8].astype(int)\n",
    "                    box_size = 25\n",
    "                    cv2.rectangle(frame, (x-box_size, y-box_size), (x+box_size, y+box_size), (255, 255, 0), 2)\n",
    "                    cv2.putText(frame, 'R_ELBOW', (x-box_size, y-box_size-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 2)\n",
    "                \n",
    "                # LEFT HAND (keypoint 9 - wrist, extend to cover glove)\n",
    "                if kpts[9][0] > 0:\n",
    "                    x, y = kpts[9].astype(int)\n",
    "                    # Larger box for boxing glove\n",
    "                    box_size = 35\n",
    "                    # Extend box forward (in front of wrist) based on elbow-wrist direction\n",
    "                    if kpts[7][0] > 0:  # If elbow is detected\n",
    "                        ex, ey = kpts[7].astype(int)\n",
    "                        # Direction from elbow to wrist\n",
    "                        dx, dy = x - ex, y - ey\n",
    "                        length = np.sqrt(dx**2 + dy**2)\n",
    "                        if length > 0:\n",
    "                            # Extend wrist position toward hand direction\n",
    "                            extend = 25\n",
    "                            x = int(x + (dx/length) * extend)\n",
    "                            y = int(y + (dy/length) * extend)\n",
    "                    cv2.rectangle(frame, (x-box_size, y-box_size), (x+box_size, y+box_size), (255, 0, 255), 2)\n",
    "                    cv2.putText(frame, 'L_HAND', (x-box_size, y-box_size-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 255), 2)\n",
    "                \n",
    "                # RIGHT HAND (keypoint 10 - wrist, extend to cover glove)\n",
    "                if kpts[10][0] > 0:\n",
    "                    x, y = kpts[10].astype(int)\n",
    "                    # Larger box for boxing glove\n",
    "                    box_size = 35\n",
    "                    # Extend box forward (in front of wrist) based on elbow-wrist direction\n",
    "                    if kpts[8][0] > 0:  # If elbow is detected\n",
    "                        ex, ey = kpts[8].astype(int)\n",
    "                        # Direction from elbow to wrist\n",
    "                        dx, dy = x - ex, y - ey\n",
    "                        length = np.sqrt(dx**2 + dy**2)\n",
    "                        if length > 0:\n",
    "                            # Extend wrist position toward hand direction\n",
    "                            extend = 25\n",
    "                            x = int(x + (dx/length) * extend)\n",
    "                            y = int(y + (dy/length) * extend)\n",
    "                    cv2.rectangle(frame, (x-box_size, y-box_size), (x+box_size, y+box_size), (128, 0, 128), 2)\n",
    "                    cv2.putText(frame, 'R_HAND', (x-box_size, y-box_size-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (128, 0, 128), 2)\n",
    "                \n",
    "                # LEFT TOES (keypoint 15 - ankle)\n",
    "                if kpts[15][0] > 0:\n",
    "                    x, y = kpts[15].astype(int)\n",
    "                    box_size = 20\n",
    "                    cv2.rectangle(frame, (x-box_size, y-box_size), (x+box_size, y+box_size), (0, 128, 255), 2)\n",
    "                    cv2.putText(frame, 'L_TOES', (x-box_size, y-box_size-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 128, 255), 2)\n",
    "                \n",
    "                # RIGHT TOES (keypoint 16 - ankle)\n",
    "                if kpts[16][0] > 0:\n",
    "                    x, y = kpts[16].astype(int)\n",
    "                    box_size = 20\n",
    "                    cv2.rectangle(frame, (x-box_size, y-box_size), (x+box_size, y+box_size), (255, 128, 0), 2)\n",
    "                    cv2.putText(frame, 'R_TOES', (x-box_size, y-box_size-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 128, 0), 2)\n",
    "    \n",
    "    out.write(frame)\n",
    "    frame_count += 1\n",
    "    \n",
    "    if frame_count % 30 == 0:\n",
    "        print(f\"Processed {frame_count}/{total_frames} frames ({frame_count/total_frames*100:.1f}%)\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"\\n✓ Processing complete!\")\n",
    "print(f\"Output saved to: {output_path}\")\n",
    "print(f\"\\nBody parts detected:\")\n",
    "print(\"  - HEAD (green)\")\n",
    "print(\"  - CHEST (blue)\")\n",
    "print(\"  - L_ELBOW (cyan)\")\n",
    "print(\"  - R_ELBOW (yellow)\")\n",
    "print(\"  - L_HAND (magenta)\")\n",
    "print(\"  - R_HAND (purple)\")\n",
    "print(\"  - L_TOES (orange)\")\n",
    "print(\"  - R_TOES (light orange)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
