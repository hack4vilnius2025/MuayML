{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455fd45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries successful!\n",
      "OpenCV version: 4.12.0\n",
      "\n",
      "Loading YOLOv11 pose model...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.0MB 4.4MB/s 1.4s.3s<0.1s<1.4s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.0MB 4.4MB/s 1.4s\n",
      "Model loaded successfully!\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Importing libraries successful!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "\n",
    "# Initialize YOLOv11 pose model\n",
    "print(\"\\nLoading YOLOv11 pose model...\")\n",
    "model = YOLO('yolo11n-pose.pt')  # Using YOLOv11 nano pose model\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6f1f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Found level_1: Beginner_Karate.mp4\n",
      "‚úì Found level_2: Semi_Advanced_Karate.mp4\n",
      "‚úì Found level_3: Advanced_Karate.mp4\n",
      "‚úì Found noob: Noob_Karate.mp4\n",
      "\n",
      "Keypoint mapping defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define video paths\n",
    "VIDEO_DIR = Path(r\"c:\\Users\\sapok\\Documents\\GitHub\\MuayML\")\n",
    "\n",
    "videos = {\n",
    "    'level_1': VIDEO_DIR / \"Beginner_Karate.mp4\",\n",
    "    'level_2': VIDEO_DIR / \"Semi_Advanced_Karate.mp4\",\n",
    "    'level_3': VIDEO_DIR / \"Advanced_Karate.mp4\",\n",
    "    'noob': VIDEO_DIR / \"Noob_Karate.mp4\"\n",
    "}\n",
    "\n",
    "# Verify all videos exist\n",
    "for name, path in videos.items():\n",
    "    if path.exists():\n",
    "        print(f\"‚úì Found {name}: {path.name}\")\n",
    "    else:\n",
    "        print(f\"‚úó Missing {name}: {path.name}\")\n",
    "\n",
    "# YOLO Pose keypoint indices (COCO format)\n",
    "# 0: nose, 1-2: eyes, 3-4: ears, 5: left shoulder, 6: right shoulder\n",
    "# 7: left elbow, 8: right elbow, 9: left wrist, 10: right wrist\n",
    "# 11: left hip, 12: right hip, 13: left knee, 14: right knee\n",
    "# 15: left ankle, 16: right ankle\n",
    "\n",
    "KEYPOINT_MAPPING = {\n",
    "    'head': 0,  # nose\n",
    "    'left_elbow': 7,\n",
    "    'right_elbow': 8,\n",
    "    'left_hand': 9,  # wrist\n",
    "    'right_hand': 10,\n",
    "    'left_hip': 11,\n",
    "    'right_hip': 12,\n",
    "    'chest': 5,  # approximating with left shoulder\n",
    "    'left_knee': 13,\n",
    "    'right_knee': 14,\n",
    "    'left_toe': 15,  # ankle\n",
    "    'right_toe': 16\n",
    "}\n",
    "\n",
    "print(\"\\nKeypoint mapping defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fde338b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def extract_keypoints_from_frame(frame, model, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Extract keypoints from a single frame using YOLOv11 pose detection.\n",
    "    Returns dictionary of keypoint coordinates with confidence filtering.\n",
    "    \"\"\"\n",
    "    results = model(frame, verbose=False, conf=0.5)  # Increased confidence threshold\n",
    "    \n",
    "    if len(results) > 0 and results[0].keypoints is not None:\n",
    "        keypoints = results[0].keypoints.xy.cpu().numpy()\n",
    "        confidences = results[0].keypoints.conf.cpu().numpy()\n",
    "        \n",
    "        if len(keypoints) > 0 and len(confidences) > 0:\n",
    "            # Get first person detected\n",
    "            person_keypoints = keypoints[0]\n",
    "            person_confidences = confidences[0]\n",
    "            \n",
    "            # Extract relevant keypoints with confidence filtering\n",
    "            extracted = {}\n",
    "            for name, idx in KEYPOINT_MAPPING.items():\n",
    "                x, y = person_keypoints[idx]\n",
    "                conf = person_confidences[idx]\n",
    "                \n",
    "                # Only include keypoint if detected with sufficient confidence\n",
    "                if x > 0 and y > 0 and conf >= confidence_threshold:\n",
    "                    extracted[name] = (int(x), int(y), float(conf))\n",
    "                else:\n",
    "                    extracted[name] = None\n",
    "                    \n",
    "            return extracted\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def draw_keypoint_boxes(frame, keypoints, color=(0, 255, 0), box_size=20):\n",
    "    \"\"\"\n",
    "    Draw precise boxes around detected keypoints with adaptive sizing.\n",
    "    color: (B, G, R) format - (0, 255, 0) for GREEN, (0, 0, 255) for RED\n",
    "    \"\"\"\n",
    "    # Define body-part specific box sizes for better precision\n",
    "    body_part_sizes = {\n",
    "        'head': 25,\n",
    "        'left_elbow': 18,\n",
    "        'right_elbow': 18,\n",
    "        'left_hand': 15,\n",
    "        'right_hand': 15,\n",
    "        'left_hip': 20,\n",
    "        'right_hip': 20,\n",
    "        'chest': 22,\n",
    "        'left_knee': 18,\n",
    "        'right_knee': 18,\n",
    "        'left_toe': 15,\n",
    "        'right_toe': 15\n",
    "    }\n",
    "    \n",
    "    for name, data in keypoints.items():\n",
    "        if data is not None:\n",
    "            x, y = data[0], data[1]\n",
    "            conf = data[2] if len(data) > 2 else 1.0\n",
    "            \n",
    "            # Get body-part specific box size\n",
    "            half_size = body_part_sizes.get(name, box_size) // 2\n",
    "            \n",
    "            # Draw rectangle with thickness based on confidence\n",
    "            thickness = max(2, int(conf * 3))\n",
    "            cv2.rectangle(frame, \n",
    "                         (x - half_size, y - half_size), \n",
    "                         (x + half_size, y + half_size), \n",
    "                         color, thickness)\n",
    "            \n",
    "            # Add label with confidence score\n",
    "            label = f\"{name.replace('_', ' ')}\"\n",
    "            \n",
    "            # Position label above the box\n",
    "            label_y = y - half_size - 8\n",
    "            \n",
    "            # Add background for text readability\n",
    "            (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)\n",
    "            cv2.rectangle(frame, \n",
    "                         (x - half_size, label_y - text_height - 2),\n",
    "                         (x - half_size + text_width + 2, label_y + 2),\n",
    "                         color, -1)\n",
    "            \n",
    "            cv2.putText(frame, label, \n",
    "                       (x - half_size + 1, label_y),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 0), 1)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "print(\"Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6596f349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference video processing function defined!\n"
     ]
    }
   ],
   "source": [
    "def process_reference_video(video_path, level_name, model, sample_frames=30):\n",
    "    \"\"\"\n",
    "    Process reference videos (Beginner, Semi_Advanced, Advanced) to extract keypoints.\n",
    "    Samples frames throughout the video to capture various poses.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing {level_name} video: {video_path.name}\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open {video_path}\")\n",
    "        return None\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    print(f\"  Total frames: {total_frames}, FPS: {fps}\")\n",
    "    \n",
    "    # Sample frames evenly throughout the video\n",
    "    frame_indices = np.linspace(0, total_frames - 1, sample_frames, dtype=int)\n",
    "    \n",
    "    all_keypoints = []\n",
    "    \n",
    "    for frame_idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        keypoints = extract_keypoints_from_frame(frame, model)\n",
    "        if keypoints:\n",
    "            all_keypoints.append(keypoints)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"  Extracted keypoints from {len(all_keypoints)} frames\")\n",
    "    \n",
    "    return {\n",
    "        'keypoints': all_keypoints,\n",
    "        'fps': fps,\n",
    "        'total_frames': total_frames\n",
    "    }\n",
    "\n",
    "\n",
    "# Store reference data for each level\n",
    "reference_data = {}\n",
    "\n",
    "print(\"Reference video processing function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f2785e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROCESSING REFERENCE VIDEOS\n",
      "============================================================\n",
      "\n",
      "Processing Beginner (Level 1) video: Beginner_Karate.mp4\n",
      "  Total frames: 251, FPS: 25.0\n",
      "  Extracted keypoints from 30 frames\n",
      "\n",
      "Processing Semi-Advanced (Level 2) video: Semi_Advanced_Karate.mp4\n",
      "  Total frames: 420, FPS: 25.0\n",
      "  Extracted keypoints from 30 frames\n",
      "\n",
      "Processing Semi-Advanced (Level 2) video: Semi_Advanced_Karate.mp4\n",
      "  Total frames: 420, FPS: 25.0\n",
      "  Extracted keypoints from 30 frames\n",
      "\n",
      "Processing Advanced (Level 3) video: Advanced_Karate.mp4\n",
      "  Total frames: 555, FPS: 29.97002997002997\n",
      "  Extracted keypoints from 30 frames\n",
      "\n",
      "Processing Advanced (Level 3) video: Advanced_Karate.mp4\n",
      "  Total frames: 555, FPS: 29.97002997002997\n",
      "  Extracted keypoints from 30 frames\n",
      "\n",
      "============================================================\n",
      "REFERENCE DATA EXTRACTION COMPLETE\n",
      "============================================================\n",
      "  Extracted keypoints from 30 frames\n",
      "\n",
      "============================================================\n",
      "REFERENCE DATA EXTRACTION COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Process all reference videos\n",
    "print(\"=\"*60)\n",
    "print(\"PROCESSING REFERENCE VIDEOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "reference_data['level_1'] = process_reference_video(videos['level_1'], 'Beginner (Level 1)', model)\n",
    "reference_data['level_2'] = process_reference_video(videos['level_2'], 'Semi-Advanced (Level 2)', model)\n",
    "reference_data['level_3'] = process_reference_video(videos['level_3'], 'Advanced (Level 3)', model)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REFERENCE DATA EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1eccf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose comparison functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def calculate_keypoint_distance(kp1, kp2):\n",
    "    \"\"\"Calculate Euclidean distance between two keypoints.\"\"\"\n",
    "    if kp1 is None or kp2 is None:\n",
    "        return float('inf')\n",
    "    \n",
    "    # Extract x, y coordinates (ignoring confidence if present)\n",
    "    x1, y1 = kp1[0], kp1[1]\n",
    "    x2, y2 = kp2[0], kp2[1]\n",
    "    \n",
    "    return np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "\n",
    "def compare_poses_with_level1(noob_keypoints, level1_keypoints_list):\n",
    "    \"\"\"\n",
    "    Compare noob keypoints ONLY with Level 1 (Beginner) reference keypoints.\n",
    "    Returns: dict with match status for each keypoint and overall match percentage.\n",
    "    \"\"\"\n",
    "    if noob_keypoints is None or not level1_keypoints_list:\n",
    "        return None\n",
    "    \n",
    "    keypoint_matches = {}\n",
    "    match_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    # Body-part specific thresholds for more accurate matching\n",
    "    body_part_thresholds = {\n",
    "        'head': 60,\n",
    "        'left_elbow': 80,\n",
    "        'right_elbow': 80,\n",
    "        'left_hand': 100,\n",
    "        'right_hand': 100,\n",
    "        'left_hip': 70,\n",
    "        'right_hip': 70,\n",
    "        'chest': 60,\n",
    "        'left_knee': 80,\n",
    "        'right_knee': 80,\n",
    "        'left_toe': 100,\n",
    "        'right_toe': 100\n",
    "    }\n",
    "    \n",
    "    # For each keypoint in the noob's pose\n",
    "    for keypoint_name in KEYPOINT_MAPPING.keys():\n",
    "        noob_kp = noob_keypoints.get(keypoint_name)\n",
    "        \n",
    "        if noob_kp is None:\n",
    "            keypoint_matches[keypoint_name] = {'matched': False, 'distance': float('inf'), 'confidence': 0}\n",
    "            total_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Get confidence if available\n",
    "        conf = noob_kp[2] if len(noob_kp) > 2 else 1.0\n",
    "        \n",
    "        # Find the best match from Level 1 reference frames ONLY\n",
    "        best_distance = float('inf')\n",
    "        \n",
    "        for ref_keypoints in level1_keypoints_list:\n",
    "            ref_kp = ref_keypoints.get(keypoint_name)\n",
    "            distance = calculate_keypoint_distance(noob_kp, ref_kp)\n",
    "            \n",
    "            if distance < best_distance:\n",
    "                best_distance = distance\n",
    "        \n",
    "        # Use body-part specific threshold\n",
    "        specific_threshold = body_part_thresholds.get(keypoint_name, 100)\n",
    "        \n",
    "        # Determine if this keypoint matches (considering both distance and confidence)\n",
    "        matched = best_distance < specific_threshold and conf >= 0.5\n",
    "        \n",
    "        keypoint_matches[keypoint_name] = {\n",
    "            'matched': matched,\n",
    "            'distance': best_distance,\n",
    "            'confidence': conf\n",
    "        }\n",
    "        \n",
    "        if matched:\n",
    "            match_count += 1\n",
    "        total_count += 1\n",
    "    \n",
    "    match_percentage = (match_count / total_count * 100) if total_count > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'keypoint_matches': keypoint_matches,\n",
    "        'match_percentage': match_percentage,\n",
    "        'matched_count': match_count,\n",
    "        'total_count': total_count\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Pose comparison functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3806aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 1: Creating Level 1 Reference Video\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "CREATING LEVEL 1 REFERENCE VIDEO\n",
      "============================================================\n",
      "\n",
      "Video properties:\n",
      "  Resolution: 1080x1920\n",
      "  FPS: 25.0\n",
      "  Total frames: 251\n",
      "\n",
      "Processing frames...\n",
      "  Processed 30/251 frames...\n",
      "  Processed 30/251 frames...\n",
      "  Processed 60/251 frames...\n",
      "  Processed 60/251 frames...\n",
      "  Processed 90/251 frames...\n",
      "  Processed 90/251 frames...\n",
      "  Processed 120/251 frames...\n",
      "  Processed 120/251 frames...\n",
      "  Processed 150/251 frames...\n",
      "  Processed 150/251 frames...\n",
      "  Processed 180/251 frames...\n",
      "  Processed 180/251 frames...\n",
      "  Processed 210/251 frames...\n",
      "  Processed 210/251 frames...\n",
      "  Processed 240/251 frames...\n",
      "  Processed 240/251 frames...\n",
      "\n",
      "‚úì Level 1 reference video saved to: c:\\Users\\sapok\\Documents\\GitHub\\MuayML\\level1_reference_analyzed.mp4\n",
      "‚úì Processed 251 frames\n",
      "\n",
      "============================================================\n",
      "STEP 2: Analyzing Noob Video against Level 1\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROCESSING NOOB VIDEO\n",
      "============================================================\n",
      "\n",
      "Video properties:\n",
      "  Resolution: 1080x1920\n",
      "  FPS: 25.0\n",
      "  Total frames: 270\n",
      "\n",
      "üéØ Comparing ONLY with Level 1 (Beginner) reference\n",
      "\n",
      "Processing frames...\n",
      "\n",
      "‚úì Level 1 reference video saved to: c:\\Users\\sapok\\Documents\\GitHub\\MuayML\\level1_reference_analyzed.mp4\n",
      "‚úì Processed 251 frames\n",
      "\n",
      "============================================================\n",
      "STEP 2: Analyzing Noob Video against Level 1\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROCESSING NOOB VIDEO\n",
      "============================================================\n",
      "\n",
      "Video properties:\n",
      "  Resolution: 1080x1920\n",
      "  FPS: 25.0\n",
      "  Total frames: 270\n",
      "\n",
      "üéØ Comparing ONLY with Level 1 (Beginner) reference\n",
      "\n",
      "Processing frames...\n",
      "  Processed 30/270 frames...\n",
      "  Processed 30/270 frames...\n",
      "  Processed 60/270 frames...\n",
      "  Processed 60/270 frames...\n",
      "  Processed 90/270 frames...\n",
      "  Processed 90/270 frames...\n",
      "  Processed 120/270 frames...\n",
      "  Processed 120/270 frames...\n",
      "  Processed 150/270 frames...\n",
      "  Processed 150/270 frames...\n",
      "  Processed 180/270 frames...\n",
      "  Processed 180/270 frames...\n",
      "  Processed 210/270 frames...\n",
      "  Processed 210/270 frames...\n",
      "  Processed 240/270 frames...\n",
      "  Processed 240/270 frames...\n",
      "  Processed 270/270 frames...\n",
      "\n",
      "‚úì Output video saved to: c:\\Users\\sapok\\Documents\\GitHub\\MuayML\\karate_analyzed.mp4\n",
      "‚úì Processed 270 frames\n",
      "\n",
      "============================================================\n",
      "VIDEO PROCESSING COMPLETE\n",
      "============================================================\n",
      "  Processed 270/270 frames...\n",
      "\n",
      "‚úì Output video saved to: c:\\Users\\sapok\\Documents\\GitHub\\MuayML\\karate_analyzed.mp4\n",
      "‚úì Processed 270 frames\n",
      "\n",
      "============================================================\n",
      "VIDEO PROCESSING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def create_level1_reference_video(video_path, model, output_path):\n",
    "    \"\"\"\n",
    "    Create Level 1 reference video with ALL GREEN boxes around detected keypoints.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CREATING LEVEL 1 REFERENCE VIDEO\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open {video_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"\\nVideo properties:\")\n",
    "    print(f\"  Resolution: {width}x{height}\")\n",
    "    print(f\"  FPS: {fps}\")\n",
    "    print(f\"  Total frames: {total_frames}\")\n",
    "    \n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    # Define body-part specific box sizes\n",
    "    body_part_sizes = {\n",
    "        'head': 25,\n",
    "        'left_elbow': 18,\n",
    "        'right_elbow': 18,\n",
    "        'left_hand': 15,\n",
    "        'right_hand': 15,\n",
    "        'left_hip': 20,\n",
    "        'right_hip': 20,\n",
    "        'chest': 22,\n",
    "        'left_knee': 18,\n",
    "        'right_knee': 18,\n",
    "        'left_toe': 15,\n",
    "        'right_toe': 15\n",
    "    }\n",
    "    \n",
    "    print(\"\\nProcessing frames...\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Extract keypoints\n",
    "        keypoints = extract_keypoints_from_frame(frame, model, confidence_threshold=0.6)\n",
    "        \n",
    "        if keypoints:\n",
    "            # Draw ALL boxes in GREEN\n",
    "            for keypoint_name, data in keypoints.items():\n",
    "                if data is not None:\n",
    "                    x, y = data[0], data[1]\n",
    "                    conf = data[2] if len(data) > 2 else 1.0\n",
    "                    \n",
    "                    # ALL GREEN for reference video\n",
    "                    color = (0, 255, 0)  # GREEN\n",
    "                    \n",
    "                    # Get body-part specific box size\n",
    "                    half_size = body_part_sizes.get(keypoint_name, 20) // 2\n",
    "                    \n",
    "                    # Draw rectangle\n",
    "                    thickness = 3\n",
    "                    cv2.rectangle(frame, \n",
    "                                 (x - half_size, y - half_size), \n",
    "                                 (x + half_size, y + half_size), \n",
    "                                 color, thickness)\n",
    "                    \n",
    "                    # Add label\n",
    "                    label = keypoint_name.replace('_', ' ')\n",
    "                    label_y = y - half_size - 8\n",
    "                    \n",
    "                    # Add semi-transparent background for text\n",
    "                    (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "                    \n",
    "                    overlay = frame.copy()\n",
    "                    cv2.rectangle(overlay, \n",
    "                                 (x - half_size - 2, label_y - text_height - 3),\n",
    "                                 (x - half_size + text_width + 2, label_y + 3),\n",
    "                                 color, -1)\n",
    "                    cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)\n",
    "                    \n",
    "                    cv2.putText(frame, label, \n",
    "                               (x - half_size, label_y),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            \n",
    "            # Add title overlay\n",
    "            overlay = frame.copy()\n",
    "            cv2.rectangle(overlay, (0, 0), (width, 60), (0, 0, 0), -1)\n",
    "            cv2.addWeighted(overlay, 0.5, frame, 0.5, 0, frame)\n",
    "            \n",
    "            cv2.putText(frame, \"LEVEL 1 - BEGINNER REFERENCE\", \n",
    "                       (10, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Write frame\n",
    "        out.write(frame)\n",
    "        \n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"  Processed {frame_count}/{total_frames} frames...\")\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"\\n‚úì Level 1 reference video saved to: {output_path}\")\n",
    "    print(f\"‚úì Processed {frame_count} frames\")\n",
    "\n",
    "\n",
    "def process_and_analyze_noob_video(noob_video_path, level1_reference_data, model, output_path):\n",
    "    \"\"\"\n",
    "    Process the Noob_Karate video, compare ONLY with Level 1 reference,\n",
    "    and create an annotated output video with GREEN for correct and RED for incorrect.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PROCESSING NOOB VIDEO\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(noob_video_path))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open {noob_video_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"\\nVideo properties:\")\n",
    "    print(f\"  Resolution: {width}x{height}\")\n",
    "    print(f\"  FPS: {fps}\")\n",
    "    print(f\"  Total frames: {total_frames}\")\n",
    "    print(f\"\\nüéØ Comparing ONLY with Level 1 (Beginner) reference\")\n",
    "    \n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_results = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    print(\"\\nProcessing frames...\")\n",
    "    \n",
    "    # Define body-part specific box sizes\n",
    "    body_part_sizes = {\n",
    "        'head': 25,\n",
    "        'left_elbow': 18,\n",
    "        'right_elbow': 18,\n",
    "        'left_hand': 15,\n",
    "        'right_hand': 15,\n",
    "        'left_hip': 20,\n",
    "        'right_hip': 20,\n",
    "        'chest': 22,\n",
    "        'left_knee': 18,\n",
    "        'right_knee': 18,\n",
    "        'left_toe': 15,\n",
    "        'right_toe': 15\n",
    "    }\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Extract keypoints from current frame\n",
    "        noob_keypoints = extract_keypoints_from_frame(frame, model, confidence_threshold=0.6)\n",
    "        \n",
    "        if noob_keypoints:\n",
    "            # Compare ONLY with Level 1\n",
    "            comparison = compare_poses_with_level1(noob_keypoints, level1_reference_data['keypoints'])\n",
    "            \n",
    "            if comparison:\n",
    "                # Draw boxes based on match status\n",
    "                for keypoint_name, data in noob_keypoints.items():\n",
    "                    if data is not None:\n",
    "                        x, y = data[0], data[1]\n",
    "                        conf = data[2] if len(data) > 2 else 1.0\n",
    "                        \n",
    "                        match_info = comparison['keypoint_matches'].get(keypoint_name, {})\n",
    "                        \n",
    "                        # GREEN for matched, RED for not matched\n",
    "                        if match_info.get('matched', False):\n",
    "                            color = (0, 255, 0)  # GREEN - CORRECT\n",
    "                        else:\n",
    "                            color = (0, 0, 255)  # RED - WRONG / DEVIATION\n",
    "                        \n",
    "                        # Get body-part specific box size\n",
    "                        half_size = body_part_sizes.get(keypoint_name, 20) // 2\n",
    "                        \n",
    "                        # Draw rectangle - thicker and brighter RED for wrong positions\n",
    "                        thickness = 3 if match_info.get('matched', False) else 4\n",
    "                        cv2.rectangle(frame, \n",
    "                                     (x - half_size, y - half_size), \n",
    "                                     (x + half_size, y + half_size), \n",
    "                                     color, thickness)\n",
    "                        \n",
    "                        # Add label with clear indication\n",
    "                        label = keypoint_name.replace('_', ' ')\n",
    "                        if not match_info.get('matched', False):\n",
    "                            label += \" ‚úó WRONG\"\n",
    "                        \n",
    "                        # Position label above the box\n",
    "                        label_y = y - half_size - 8\n",
    "                        \n",
    "                        # Add semi-transparent background for text\n",
    "                        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "                        \n",
    "                        overlay = frame.copy()\n",
    "                        cv2.rectangle(overlay, \n",
    "                                     (x - half_size - 2, label_y - text_height - 3),\n",
    "                                     (x - half_size + text_width + 2, label_y + 3),\n",
    "                                     color, -1)\n",
    "                        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "                        \n",
    "                        cv2.putText(frame, label, \n",
    "                                   (x - half_size, label_y),\n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                \n",
    "                # Add info overlay\n",
    "                match_pct = comparison['match_percentage']\n",
    "                matched = comparison['matched_count']\n",
    "                total = comparison['total_count']\n",
    "                \n",
    "                # Create info panel at top\n",
    "                overlay = frame.copy()\n",
    "                cv2.rectangle(overlay, (0, 0), (width, 90), (0, 0, 0), -1)\n",
    "                cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)\n",
    "                \n",
    "                # Color code the match percentage\n",
    "                if match_pct >= 70:\n",
    "                    perf_color = (0, 255, 0)  # GREEN\n",
    "                elif match_pct >= 50:\n",
    "                    perf_color = (0, 255, 255)  # YELLOW\n",
    "                else:\n",
    "                    perf_color = (0, 0, 255)  # RED\n",
    "                \n",
    "                cv2.putText(frame, f\"Match with Level 1: {match_pct:.1f}% ({matched}/{total} correct)\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, perf_color, 2, cv2.LINE_AA)\n",
    "                \n",
    "                cv2.putText(frame, f\"Frame: {frame_count}/{total_frames}\", \n",
    "                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1, cv2.LINE_AA)\n",
    "                \n",
    "                frame_results.append({\n",
    "                    'frame': frame_count,\n",
    "                    'match_percentage': match_pct,\n",
    "                    'comparison': comparison\n",
    "                })\n",
    "        \n",
    "        # Write frame to output\n",
    "        out.write(frame)\n",
    "        \n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"  Processed {frame_count}/{total_frames} frames...\")\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"\\n‚úì Output video saved to: {output_path}\")\n",
    "    print(f\"‚úì Processed {frame_count} frames\")\n",
    "    \n",
    "    return frame_results\n",
    "\n",
    "\n",
    "# Create Level 1 reference video with all GREEN boxes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: Creating Level 1 Reference Video\")\n",
    "print(\"=\"*60)\n",
    "level1_output_path = VIDEO_DIR / \"level1_reference_analyzed.mp4\"\n",
    "create_level1_reference_video(videos['level_1'], model, level1_output_path)\n",
    "\n",
    "# Process the Noob video comparing ONLY with Level 1\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: Analyzing Noob Video against Level 1\")\n",
    "print(\"=\"*60)\n",
    "noob_output_path = VIDEO_DIR / \"karate_analyzed.mp4\"\n",
    "noob_results = process_and_analyze_noob_video(videos['noob'], reference_data['level_1'], model, noob_output_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VIDEO PROCESSING COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "894c5c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GENERATING ANALYSIS REPORT\n",
      "============================================================\n",
      "\n",
      "üìä PERFORMANCE ANALYSIS (vs Level 1 Beginner)\n",
      "------------------------------------------------------------\n",
      "Total Frames Analyzed: 270\n",
      "Average Match Percentage: 87.31%\n",
      "\n",
      "‚≠ê Overall Grade: 87/100\n",
      "\n",
      "üí¨ ASSESSMENT\n",
      "------------------------------------------------------------\n",
      "‚úÖ GOOD! Your form is solid with some minor deviations from Level 1.\n",
      "\n",
      "üéØ KEYPOINT ANALYSIS (Body Part Performance)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Match rates by body part:\n",
      "Body Part          Match Rate   Status     Avg Distance (px)\n",
      "------------------------------------------------------------\n",
      "head               100.0% (270/270) ‚úì GOOD       22.5\n",
      "left_elbow          81.1% (219/270) ‚úì GOOD       52.0\n",
      "right_elbow         96.3% (260/270) ‚úì GOOD       28.0\n",
      "left_hand           62.2% (168/270) ‚ö† OK         91.7\n",
      "right_hand          99.6% (269/270) ‚úì GOOD       20.7\n",
      "left_hip            99.3% (268/270) ‚úì GOOD       27.0\n",
      "right_hip           98.5% (266/270) ‚úì GOOD       21.9\n",
      "chest               92.2% (249/270) ‚úì GOOD       38.7\n",
      "left_knee           95.9% (259/270) ‚úì GOOD       35.8\n",
      "right_knee          83.7% (226/270) ‚úì GOOD       42.2\n",
      "left_toe            75.6% (204/270) ‚ö† OK         49.4\n",
      "right_toe           63.3% (171/270) ‚ö† OK         79.6\n",
      "\n",
      "üìã RECOMMENDATIONS\n",
      "------------------------------------------------------------\n",
      "Great job! All body parts show good form.\n",
      "\n",
      "============================================================\n",
      "üìπ OUTPUT VIDEOS:\n",
      "   1. Level 1 Reference: level1_reference_analyzed.mp4\n",
      "   2. Noob Analysis: karate_analyzed.mp4\n",
      "============================================================\n",
      "\n",
      "‚úÖ ANALYSIS COMPLETE!\n",
      "\n",
      "üéØ Summary: You scored 87/100 compared to Level 1 Beginner techniques.\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive analysis and grading\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING ANALYSIS REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if noob_results:\n",
    "    # Calculate overall statistics\n",
    "    total_frames_analyzed = len(noob_results)\n",
    "    \n",
    "    if total_frames_analyzed > 0:\n",
    "        avg_match_percentage = np.mean([r['match_percentage'] for r in noob_results])\n",
    "        \n",
    "        # Calculate grade (1-100) based on match with Level 1\n",
    "        grade = int(avg_match_percentage)\n",
    "        \n",
    "        # Generate detailed report\n",
    "        print(\"\\nüìä PERFORMANCE ANALYSIS (vs Level 1 Beginner)\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Total Frames Analyzed: {total_frames_analyzed}\")\n",
    "        print(f\"Average Match Percentage: {avg_match_percentage:.2f}%\")\n",
    "        print(f\"\\n‚≠ê Overall Grade: {grade}/100\")\n",
    "        \n",
    "        # Performance assessment\n",
    "        print(\"\\nüí¨ ASSESSMENT\")\n",
    "        print(\"-\" * 60)\n",
    "        if grade >= 90:\n",
    "            assessment = \"EXCELLENT! Your karate form closely matches the Level 1 beginner techniques.\"\n",
    "            emoji = \"üèÜ\"\n",
    "        elif grade >= 75:\n",
    "            assessment = \"GOOD! Your form is solid with some minor deviations from Level 1.\"\n",
    "            emoji = \"‚úÖ\"\n",
    "        elif grade >= 60:\n",
    "            assessment = \"FAIR. Your form shows promise but needs improvement in several areas.\"\n",
    "            emoji = \"‚ö†Ô∏è\"\n",
    "        elif grade >= 40:\n",
    "            assessment = \"NEEDS WORK. Significant differences from Level 1 techniques detected.\"\n",
    "            emoji = \"‚ùå\"\n",
    "        else:\n",
    "            assessment = \"BEGINNER. Focus on mastering basic Level 1 form and positioning.\"\n",
    "            emoji = \"üìö\"\n",
    "        \n",
    "        print(f\"{emoji} {assessment}\")\n",
    "        \n",
    "        # Keypoint-specific analysis\n",
    "        print(\"\\nüéØ KEYPOINT ANALYSIS (Body Part Performance)\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Aggregate keypoint match rates\n",
    "        keypoint_stats = {kp: {'matched': 0, 'total': 0, 'avg_distance': []} for kp in KEYPOINT_MAPPING.keys()}\n",
    "        \n",
    "        for result in noob_results:\n",
    "            for kp_name, match_info in result['comparison']['keypoint_matches'].items():\n",
    "                keypoint_stats[kp_name]['total'] += 1\n",
    "                if match_info['matched']:\n",
    "                    keypoint_stats[kp_name]['matched'] += 1\n",
    "                if match_info['distance'] != float('inf'):\n",
    "                    keypoint_stats[kp_name]['avg_distance'].append(match_info['distance'])\n",
    "        \n",
    "        print(\"\\nMatch rates by body part:\")\n",
    "        print(f\"{'Body Part':<18} {'Match Rate':<12} {'Status':<10} {'Avg Distance (px)'}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for kp_name, stats in keypoint_stats.items():\n",
    "            if stats['total'] > 0:\n",
    "                match_rate = (stats['matched'] / stats['total']) * 100\n",
    "                avg_dist = np.mean(stats['avg_distance']) if stats['avg_distance'] else 0\n",
    "                \n",
    "                if match_rate >= 80:\n",
    "                    status = \"‚úì GOOD\"\n",
    "                elif match_rate >= 60:\n",
    "                    status = \"‚ö† OK\"\n",
    "                else:\n",
    "                    status = \"‚úó POOR\"\n",
    "                \n",
    "                print(f\"{kp_name:<18} {match_rate:>5.1f}% ({stats['matched']:>3}/{stats['total']:<3}) {status:<10} {avg_dist:>6.1f}\")\n",
    "        \n",
    "        # Recommendations\n",
    "        print(\"\\nüìã RECOMMENDATIONS\")\n",
    "        print(\"-\" * 60)\n",
    "        poor_keypoints = [kp for kp, stats in keypoint_stats.items() \n",
    "                         if stats['total'] > 0 and (stats['matched'] / stats['total']) < 0.6]\n",
    "        \n",
    "        if poor_keypoints:\n",
    "            print(\"Focus on improving these body parts:\")\n",
    "            for kp in poor_keypoints[:5]:  # Show top 5\n",
    "                print(f\"  ‚Ä¢ {kp.replace('_', ' ').title()}\")\n",
    "        else:\n",
    "            print(\"Great job! All body parts show good form.\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"üìπ OUTPUT VIDEOS:\")\n",
    "        print(f\"   1. Level 1 Reference: level1_reference_analyzed.mp4\")\n",
    "        print(f\"   2. Noob Analysis: karate_analyzed.mp4\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(\"\\n‚úÖ ANALYSIS COMPLETE!\")\n",
    "        print(f\"\\nüéØ Summary: You scored {grade}/100 compared to Level 1 Beginner techniques.\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results to analyze. Check if the Noob video was processed correctly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
